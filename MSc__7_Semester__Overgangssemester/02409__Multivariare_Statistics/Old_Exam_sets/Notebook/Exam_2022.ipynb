{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4dd9734",
   "metadata": {},
   "source": [
    "# Exam 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e67eed",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "\n",
    "<img src=\"SymPyBilleder/2025-11-10-10-32-18.png\" width=\"750\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "391d19f5",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     name           mfr    type      calories      protein           fat       \n",
       " Length:76          G:22   C:74   Min.   : 50   Min.   :1.000   Min.   :0.000  \n",
       " Class :character   K:23   H: 2   1st Qu.:100   1st Qu.:2.000   1st Qu.:0.000  \n",
       " Mode  :character   N: 6          Median :110   Median :2.500   Median :1.000  \n",
       "                    P: 9          Mean   :107   Mean   :2.526   Mean   :1.013  \n",
       "                    Q: 8          3rd Qu.:110   3rd Qu.:3.000   3rd Qu.:2.000  \n",
       "                    R: 8          Max.   :160   Max.   :6.000   Max.   :5.000  \n",
       "     sodium          fiber           carbo           sugars      \n",
       " Min.   :  0.0   Min.   : 0.00   Min.   :-1.00   Min.   :-1.000  \n",
       " 1st Qu.:133.8   1st Qu.: 1.00   1st Qu.:12.00   1st Qu.: 3.000  \n",
       " Median :180.0   Median : 2.00   Median :14.00   Median : 7.000  \n",
       " Mean   :161.8   Mean   : 2.18   Mean   :14.58   Mean   : 6.974  \n",
       " 3rd Qu.:212.5   3rd Qu.: 3.00   3rd Qu.:17.00   3rd Qu.:11.000  \n",
       " Max.   :320.0   Max.   :14.00   Max.   :23.00   Max.   :15.000  \n",
       "     potass          vitamins          shelf           weight    \n",
       " Min.   : -1.00   Min.   :  0.00   Min.   :1.000   Min.   :0.50  \n",
       " 1st Qu.: 40.00   1st Qu.: 25.00   1st Qu.:1.000   1st Qu.:1.00  \n",
       " Median : 90.00   Median : 25.00   Median :2.000   Median :1.00  \n",
       " Mean   : 96.09   Mean   : 28.29   Mean   :2.211   Mean   :1.03  \n",
       " 3rd Qu.:120.00   3rd Qu.: 25.00   3rd Qu.:3.000   3rd Qu.:1.00  \n",
       " Max.   :330.00   Max.   :100.00   Max.   :3.000   Max.   :1.50  \n",
       "      cups            rating     \n",
       " Min.   :0.2500   Min.   :18.04  \n",
       " 1st Qu.:0.6700   1st Qu.:32.93  \n",
       " Median :0.7500   Median :40.25  \n",
       " Mean   :0.8187   Mean   :42.51  \n",
       " 3rd Qu.:1.0000   3rd Qu.:50.78  \n",
       " Max.   :1.5000   Max.   :93.70  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "breakfast <- data.frame(\"name\"= c(\"100Bran\",\"100NaturalBran\",\"AllBran\",\"AllBranFiber\",\"AlmondDelight\",\"AppleCinnamonCheerios\",\"AppleJacks\",\"Basic4\",\"BranChex\",\"BranFlakes\",\"CapCrunch\",\"Cheerios\",\"CinnamonToastCrunch\",\"Clusters\",\"CocoaPuffs\",\"CornChex\",\"CornFlakes\",\"CornPops\",\"CountChocula\",\"CracklinOatBran\",\"CreamWheat\",\"Crispix\",\"CrispyWheatRaisins\",\"DoubleChex\",\"FrootLoops\",\"FrostedFlakes\",\"FrostedMiniWheats\",\"FruitFibreDates\",\"FruitfulBran\",\"FruityPebbles\",\"GoldenCrisp\",\"GoldenGrahams\",\"GrapeNutsFlakes\",\"GrapeNuts\",\"GreatGrainsPecan\",\"HoneyGraham\",\"HoneyNutCheerios\",\"Honeycomb\",\"JustRightCrunchyNuggets\",\"JustRightFruitNut\",\"Kix\",\"Life\",\"LuckyCharms\",\"MuesliRaisinsDatesAlmonds\",\"MuesliRaisinsPeachesPecans\",\"MueslixCrispyBlend\",\"MultiGrainCheerios\",\"NutHoneyCrunch\",\"NutriGrainAlmondRaisin\",\"NutrigrainWheat\",\"OatmealRaisinCrisp\",\"PostNatRaisinBran\",\"Product19\",\"PuffedRice\",\"PuffedWheat\",\"QuakerOatSquares\",\"QuakerOatmeal\",\"RaisinBran\",\"RaisinNutBran\",\"RaisinSquares\",\"RiceChex\",\"RiceKrispies\",\"ShreddedWheat\",\"ShreddedWheatBran\",\"ShreddedWheatspoonsize\",\"Smacks\",\"SpecialK\",\"StrawberryFruitWheats\",\"TotalCornFlakes\",\"TotalRaisinBran\",\"TotalWholeGrain\",\"Triples\",\"Trix\",\"WheatChex\",\"Wheaties\",\"WheatiesHoneyGold\"),\n",
    "                        \"mfr\" = factor(c(3,5,2,2,6,1,2,1,6,4,5,1,1,1,1,6,2,2,1,2,3,2,1,6,2,2,2,4,2,4,4,1,4,4,4,5,1,4,2,2,1,5,1,6,6,2,1,2,2,2,1,4,2,5,5,5,5,2,1,2,6,2,3,3,3,2,2,3,1,1,1,1,1,6,1,1), levels= c(1,2,3,4,5,6), labels = c(\"G\", \"K\", \"N\", \"P\", \"Q\", \"R\")),\n",
    "                        \"type\" = factor(c(\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"H\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"H\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\")),\n",
    "                        \"calories\" = c(70,120,70,50,110,110,110,130,90,90,120,110,120,110,110,110,100,110,110,110,100,110,100,100,110,110,100,120,120,110,100,110,100,110,120,120,110,110,110,140,110,100,110,150,150,160,100,120,140,90,130,120,100,50,50,100,100,120,100,90,110,110,80,90,90,110,110,90,110,140,100,110,110,100,100,110),\n",
    "                        \"protein\" = c(4,3,4,4,2,2,2,3,2,3,1,6,1,3,1,2,2,1,1,3,3,2,2,2,2,1,3,3,3,1,2,1,3,3,3,1,3,1,2,3,2,4,2,4,4,3,2,2,3,3,3,3,3,1,2,4,5,3,3,2,1,2,2,3,3,2,6,2,2,3,3,2,1,3,3,2),\n",
    "                        \"fat\" = c(1,5,1,0,2,2,0,2,1,0,2,2,3,2,1,0,0,0,1,3,0,0,1,0,1,0,0,2,0,1,0,1,1,0,3,2,1,0,1,1,1,2,1,3,3,2,1,1,2,0,2,1,0,0,0,1,2,1,2,0,0,0,0,0,0,1,0,0,1,1,1,1,1,1,1,1),\n",
    "                        \"sodium\" = c(130,15,260,140,200,180,125,210,200,210,220,290,210,140,180,280,290,90,180,140,80,220,140,190,125,200,0,160,240,135,45,280,140,170,75,220,250,180,170,170,260,150,180,95,150,150,220,190,220,170,170,200,320,0,0,135,0,210,140,0,240,290,0,0,0,70,230,15,200,190,200,250,140,230,200,200),\n",
    "                        \"fiber\" = c(10,2,9,14,1,1.5,1,2,4,5,0,2,0,2,0,0,1,1,0,4,1,1,2,1,1,1,3,5,5,0,0,0,3,3,3,1,1.5,0,1,2,0,2,0,3,3,3,2,0,3,3,1.5,6,1,0,1,2,2.7,5,2.5,2,0,0,3,4,3,1,1,3,0,4,3,0,0,3,3,1),\n",
    "                        \"carbo\" = c(5,8,7,8,14,10.5,11,18,15,13,12,17,13,13,12,22,21,13,12,10,21,21,11,18,11,14,14,12,14,13,11,15,15,17,13,12,11.5,14,17,20,21,12,12,16,16,17,15,15,21,18,13.5,11,20,13,10,14,-1,14,10.5,15,23,22,16,19,20,9,16,15,21,15,16,21,13,17,17,16),\n",
    "                        \"sugars\" = c(6,8,5,0,8,10,14,8,6,5,12,1,9,7,13,3,2,12,13,7,0,3,10,5,13,11,7,10,12,12,15,9,5,3,4,11,10,11,6,9,3,6,12,11,11,13,6,9,7,2,10,14,3,0,0,6,-1,12,8,6,2,3,0,0,0,15,3,5,3,14,3,3,12,3,3,8),\n",
    "                        \"potass\" = c(280,135,320,330,-1,70,30,100,125,190,35,105,45,105,55,25,35,20,65,160,-1,30,120,80,30,25,100,200,190,25,40,45,85,90,100,45,90,35,60,95,40,95,55,170,170,160,90,40,130,90,120,260,45,15,50,110,110,240,140,110,30,35,95,140,120,40,55,90,35,230,110,60,25,115,110,60),\n",
    "                        \"vitamins\" = c(25,0,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,0,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,100,100,25,25,25,25,25,25,25,25,25,25,25,25,100,0,0,25,0,25,25,25,25,25,0,0,0,25,25,25,100,100,100,25,25,25,25,25),\n",
    "                        \"shelf\" = c(3,3,3,3,3,1,2,3,1,3,2,1,2,3,2,1,1,2,2,3,2,3,3,3,2,1,2,3,3,2,1,2,3,3,3,2,1,1,3,3,2,2,2,3,3,3,1,2,3,3,3,3,3,3,3,3,1,2,3,3,1,1,1,1,1,2,1,2,3,3,3,3,2,1,1,1),\n",
    "                        \"weight\" = c(1,1,1,1,1,1,1,1.33,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1.25,1.33,1,1,1,1,1,1,1,1,1,1,1.3,1,1,1,1,1,1.5,1,1,1.33,1,1.25,1.33,1,0.5,0.5,1,1,1.33,1,1,1,1,0.83,1,1,1,1,1,1,1.5,1,1,1,1,1,1),\n",
    "                        \"cups\" = c(0.33,1,0.33,0.5,0.75,0.75,1,0.75,0.67,0.67,0.75,1.25,0.75,0.5,1,1,1,1,1,0.5,1,1,0.75,0.75,1,0.75,0.8,0.67,0.67,0.75,0.88,0.75,0.88,0.25,0.33,1,0.75,1.33,1,0.75,1.5,0.67,1,1,1,0.67,1,0.67,0.67,1,0.5,0.67,1,1,1,0.5,0.67,0.75,0.5,0.5,1.13,1,1,0.67,0.67,0.75,1,1,1,1,1,0.75,1,0.67,1,0.75),\n",
    "                        \"rating\" = c(68.402973,33.983679,59.425505,93.704912,34.384843,29.509541,33.174094,37.038562,49.120253,53.313813,18.042851,50.764999,19.823573,40.400208,22.736446,41.445019,45.863324,35.782791,22.396513,40.448772,64.533816,46.895644,36.176196,44.330856,32.207582,31.435973,58.345141,40.917047,41.015492,28.025765,35.252444,23.804043,52.076897,53.371007,45.811716,21.871292,31.072217,28.742414,36.523683,36.471512,39.241114,45.328074,26.734515,37.136863,34.139765,30.313351,40.105965,29.924285,40.69232,59.642837,30.450843,37.840594,41.50354,60.756112,63.005645,49.511874,50.828392,39.259197,39.7034,55.333142,41.998933,40.560159,68.235885,74.472949,72.801787,31.230054,53.131324,59.363993,38.839746,28.592785,46.658844,39.106174,27.753301,49.787445,51.592193,36.187559))\n",
    "\n",
    "summary(breakfast)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533f33cf",
   "metadata": {},
   "source": [
    "### Question 1.1 \n",
    "\n",
    "<img src=\"SymPyBilleder/2025-11-10-10-32-39.png\" width=\"750\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5839188e",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "          Df  Wilks approx F num Df den Df   Pr(>F)    \n",
       "mfr        5 0.1661   3.0774     45 280.44 7.46e-09 ***\n",
       "Residuals 70                                           \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make sure mfr is a factor (it already is in your data)\n",
    "is.factor(breakfast$mfr)\n",
    "\n",
    "# MANOVA: all nine responses vs. mfr\n",
    "fit <- manova(cbind(calories, protein, fat, sodium, fiber, carbo, sugars, potass, rating) ~ mfr,\n",
    "              data = breakfast)\n",
    "\n",
    "# Wilks' Lambda table\n",
    "summary(fit, test = \"Wilks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20cf7d1d",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.166096140868286"
      ],
      "text/latex": [
       "0.166096140868286"
      ],
      "text/markdown": [
       "0.166096140868286"
      ],
      "text/plain": [
       "[1] 0.1660961"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wilks <- summary(fit, test = \"Wilks\")$stats[1, \"Wilks\"]\n",
    "wilks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e99254",
   "metadata": {},
   "source": [
    "**Answer**\\\n",
    "Option 2 - $0.1661$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c992a046",
   "metadata": {},
   "source": [
    "### Question 1.2\n",
    "\n",
    "<img src=\"SymPyBilleder/2025-11-10-10-43-21.png\" width=\"750\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "777f4f6d",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: carData\n",
      "\n",
      "Warning message:\n",
      "“package ‘carData’ was built under R version 4.5.1”\n"
     ]
    }
   ],
   "source": [
    "library(car)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8673530",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Variable: calories \n",
      "Anova Table (Type III tests)\n",
      "\n",
      "Response: calories\n",
      "            Sum Sq Df  F value  Pr(>F)    \n",
      "(Intercept) 272841  1 791.0993 < 2e-16 ***\n",
      "mfr           4662  5   2.7033 0.02724 *  \n",
      "Residuals    24142 70                     \n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
      "\n",
      "Variable: protein \n",
      "Anova Table (Type III tests)\n",
      "\n",
      "Response: protein\n",
      "             Sum Sq Df F value    Pr(>F)    \n",
      "(Intercept) 118.227  1 95.2122 1.097e-14 ***\n",
      "mfr           2.027  5  0.3264    0.8954    \n",
      "Residuals    86.921 70                      \n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
      "\n",
      "Variable: fat \n",
      "Anova Table (Type III tests)\n",
      "\n",
      "Response: fat\n",
      "            Sum Sq Df F value   Pr(>F)    \n",
      "(Intercept) 40.909  1 46.7217 2.49e-09 ***\n",
      "mfr         15.695  5  3.5851 0.006057 ** \n",
      "Residuals   61.291 70                     \n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
      "\n",
      "Variable: sodium \n",
      "Anova Table (Type III tests)\n",
      "\n",
      "Response: sodium\n",
      "            Sum Sq Df  F value    Pr(>F)    \n",
      "(Intercept) 884005  1 188.8653 < 2.2e-16 ***\n",
      "mfr         180643  5   7.7188 7.925e-06 ***\n",
      "Residuals   327643 70                       \n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
      "\n",
      "Variable: fiber \n",
      "Anova Table (Type III tests)\n",
      "\n",
      "Response: fiber\n",
      "            Sum Sq Df F value  Pr(>F)  \n",
      "(Intercept)  35.64  1  6.7020 0.01170 *\n",
      "mfr          54.81  5  2.0617 0.08054 .\n",
      "Residuals   372.21 70                  \n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
      "\n",
      "Variable: carbo \n",
      "Anova Table (Type III tests)\n",
      "\n",
      "Response: carbo\n",
      "            Sum Sq Df  F value  Pr(>F)    \n",
      "(Intercept) 4771.6  1 300.5342 < 2e-16 ***\n",
      "mfr          278.1  5   3.5034 0.00696 ** \n",
      "Residuals   1111.4 70                     \n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
      "\n",
      "Variable: sugars \n",
      "Anova Table (Type III tests)\n",
      "\n",
      "Response: sugars\n",
      "             Sum Sq Df F value    Pr(>F)    \n",
      "(Intercept) 1392.05  1 78.6231 4.638e-13 ***\n",
      "mfr          246.58  5  2.7853   0.02369 *  \n",
      "Residuals   1239.37 70                      \n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
      "\n",
      "Variable: potass \n",
      "Anova Table (Type III tests)\n",
      "\n",
      "Response: potass\n",
      "            Sum Sq Df F value    Pr(>F)    \n",
      "(Intercept) 159801  1 30.0793 6.197e-07 ***\n",
      "mfr          14330  5  0.5395    0.7457    \n",
      "Residuals   371886 70                      \n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
      "\n",
      "Variable: rating \n",
      "Anova Table (Type III tests)\n",
      "\n",
      "Response: rating\n",
      "             Sum Sq Df F value    Pr(>F)    \n",
      "(Intercept) 26164.0  1 193.344 < 2.2e-16 ***\n",
      "mfr          5373.7  5   7.942 5.683e-06 ***\n",
      "Residuals    9472.7 70                      \n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n"
     ]
    }
   ],
   "source": [
    "# List of numeric dependent variables\n",
    "vars <- c(\"calories\", \"protein\", \"fat\", \"sodium\", \"fiber\",\n",
    "          \"carbo\", \"sugars\", \"potass\", \"rating\")\n",
    "\n",
    "# Calculate Type III SS for each variable\n",
    "for (v in vars) {\n",
    "  model <- lm(as.formula(paste(v, \"~ mfr\")), data = breakfast)\n",
    "  cat(\"\\nVariable:\", v, \"\\n\")\n",
    "  print(Anova(model, type = 3))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d4f9cc",
   "metadata": {},
   "source": [
    "Look at the “Sum Sq (mfr)” column\n",
    "\n",
    "Whichever variable shows the largest Type III SS for mfr has the biggest difference between manufacturers.\n",
    "\n",
    "When this is run on your dataset, you’ll see the largest Type III SS appears for sodium — the sodium content varies most strongly between cereal manufacturers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14a0e6e",
   "metadata": {},
   "source": [
    "**Answer**\\\n",
    "Option D - Sodium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6b52fa3",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      sodium       potass       rating     calories        carbo       sugars \n",
      "1.806426e+05 1.432994e+04 5.373697e+03 4.661765e+03 2.781234e+02 2.465768e+02 \n",
      "       fiber          fat      protein \n",
      "5.481267e+01 1.569545e+01 2.026694e+00 \n",
      "\n",
      "Largest Type III SS: sodium = 180642.6 \n"
     ]
    }
   ],
   "source": [
    "# Make Type III work cleanly\n",
    "options(contrasts = c(\"contr.sum\", \"contr.poly\"))\n",
    "library(car)\n",
    "\n",
    "vars <- c(\"calories\",\"protein\",\"fat\",\"sodium\",\"fiber\",\"carbo\",\"sugars\",\"potass\",\"rating\")\n",
    "\n",
    "# helper: return Type III SS for the mfr effect for one response\n",
    "type3_ss_mfr <- function(y) {\n",
    "  fit <- lm(reformulate(\"mfr\", response = y), data = breakfast)\n",
    "  a <- Anova(fit, type = 3)\n",
    "  # pick the non-intercept row robustly\n",
    "  mfr_row <- setdiff(rownames(a), \"(Intercept)\")[1]\n",
    "  as.numeric(a[mfr_row, \"Sum Sq\"])\n",
    "}\n",
    "\n",
    "# compute and sort\n",
    "ss_vec <- setNames(sapply(vars, type3_ss_mfr), vars)\n",
    "ss_sorted <- sort(ss_vec, decreasing = TRUE)\n",
    "\n",
    "print(ss_sorted)\n",
    "cat(\"\\nLargest Type III SS:\", names(ss_sorted)[1], \"=\", ss_sorted[1], \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5825b40",
   "metadata": {},
   "source": [
    "#### Solution code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7613a7c2",
   "metadata": {},
   "source": [
    "### Question 1.3\n",
    "\n",
    "<img src=\"SymPyBilleder/2025-11-10-10-49-12.png\" width=\"750\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f178f60b",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U(9,5,70)\n"
     ]
    }
   ],
   "source": [
    "# 1) U-distribution parameters for Wilks' Lambda in one-way MANOVA\n",
    "p  <- 9                                # number of responses\n",
    "g  <- nlevels(breakfast$mfr)           # number of groups (manufacturers)\n",
    "n  <- nrow(breakfast)                  # total sample size\n",
    "\n",
    "U_params <- c(p, g - 1, n - g)\n",
    "cat(sprintf(\"U(%d,%d,%d)\\n\", U_params[1], U_params[2], U_params[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "158db093",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          Df  Wilks approx F num Df den Df   Pr(>F)    \n",
       "mfr        5 0.1661   3.0774     45 280.44 7.46e-09 ***\n",
       "Residuals 70                                           \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2) Verify by fitting MANOVA and seeing the F-approx with its dfs\n",
    "fit <- manova(cbind(calories, protein, fat, sodium, fiber, carbo, sugars, potass, rating) ~ mfr,\n",
    "              data = breakfast)\n",
    "summary(fit, test = \"Wilks\")\n",
    "# This prints Wilks' Λ with its approximate F and numerator/denominator dfs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359cea23",
   "metadata": {},
   "source": [
    "**Model context**\n",
    "\n",
    "We tested whether the mean vectors differ between the 6 manufacturers (`mfr`) over $9$ response variables.\n",
    "That’s a **one-way MANOVA** with:\n",
    "\n",
    "* $g = 6$ groups (manufacturers)\n",
    "* $p = 9$ dependent variables\n",
    "* $n = 77$ total cereals (so residual $df \\approx 71$, but check below)\n",
    "\n",
    "**Degrees of freedom for Wilks’ Lambda test**\n",
    "\n",
    "For the MANOVA $Y = \\mu + mfr + \\epsilon$,\n",
    "the **approximate F transformation** of Wilks’ Lambda uses:\n",
    "\n",
    "$$\n",
    "U(p, g-1, n-g)\n",
    "$$\n",
    "notation or equivalent $F$-approximation $F(\\nu_1, \\nu_2)$.\n",
    "\n",
    "For a **one-way MANOVA** with $p = 9$ and $g-1 = 5$ manufacturer df:\n",
    "\n",
    "$$\n",
    "U(9, 5, 70)\n",
    "$$\n",
    "\n",
    "is the correct distribution for the test statistic under $H_0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee91242",
   "metadata": {},
   "source": [
    "#### Solution code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "493e5f44",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of manufacturers: 6 \n",
      "Number of observations: 76 \n",
      "Number of variables: 9 \n"
     ]
    }
   ],
   "source": [
    "Q13_variables <- c(\"calories\", \"protein\", \"fat\", \"sodium\", \"fiber\", \"carbo\", \"sugars\", \"potass\",\"rating\")\n",
    "Q13_num_variables <- length(Q13_variables)\n",
    "cat(\"Number of manufacturers:\", length(unique(breakfast$mfr)),\"\\n\")\n",
    "cat(\"Number of observations:\", nrow(breakfast), \"\\n\")\n",
    "cat(\"Number of variables:\", Q13_num_variables, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d968619c",
   "metadata": {},
   "source": [
    "### Question 1.4 \n",
    "\n",
    "<img src=\"SymPyBilleder/2025-11-10-10-59-41.png\" width=\"750\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96d0603c",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 3 Ucrit = 0.0025 \n",
      "n = 4 Ucrit = 0.05 \n",
      "n = 5 Ucrit = 0.1357 \n",
      "n = 6 Ucrit = 0.2236 \n",
      "=> Significant at 5% level for n = 6 \n"
     ]
    }
   ],
   "source": [
    "alpha <- 0.05\n",
    "u_obs <- 0.2\n",
    "s <- 1\n",
    "r <- 2\n",
    "\n",
    "# test successive n values until Ucrit > u_obs\n",
    "for (n in 3:20) {\n",
    "  # transform to approximate F statistic\n",
    "  f_crit <- qf(1 - alpha, r, n - 2)\n",
    "  u_crit <- 1 / (1 + (r / (n - 2)) * f_crit)  # critical U\n",
    "  cat(\"n =\", n, \"Ucrit =\", round(u_crit, 4), \"\\n\")\n",
    "  if (u_obs <= u_crit) {\n",
    "    cat(\"=> Significant at 5% level for n =\", n, \"\\n\")\n",
    "    break\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "738e3d70",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    n     Ucrit significant\n",
      "1   3 0.0025000       FALSE\n",
      "2   4 0.0500000       FALSE\n",
      "3   5 0.1357209       FALSE\n",
      "4   6 0.2236068        TRUE\n",
      "5   7 0.3017088        TRUE\n",
      "6   8 0.3684031        TRUE\n",
      "7   9 0.4248906        TRUE\n",
      "8  10 0.4728708        TRUE\n",
      "9  11 0.5139043        TRUE\n",
      "10 12 0.5492803        TRUE\n",
      "11 13 0.5800282        TRUE\n",
      "12 14 0.6069622        TRUE\n",
      "13 15 0.6307272        TRUE\n",
      "14 16 0.6518363        TRUE\n",
      "15 17 0.6707016        TRUE\n",
      "16 18 0.6876560        TRUE\n",
      "17 19 0.7029714        TRUE\n",
      "18 20 0.7168712        TRUE\n",
      "Smallest n with significance: 6 \n"
     ]
    }
   ],
   "source": [
    "alpha <- 0.05\n",
    "u_obs <- 0.2\n",
    "s <- 1; r <- 2\n",
    "\n",
    "u_crit <- function(n) {\n",
    "  df2 <- n - 2\n",
    "  fcrit <- qf(1 - alpha, r, df2)\n",
    "  1 / (1 + (r / df2) * fcrit)\n",
    "}\n",
    "\n",
    "# show table and minimum n\n",
    "ns <- 3:20\n",
    "tab <- data.frame(n = ns,\n",
    "                  Ucrit = sapply(ns, u_crit),\n",
    "                  significant = u_obs <= sapply(ns, u_crit))\n",
    "print(tab)\n",
    "\n",
    "min_n <- min(tab$n[tab$significant])\n",
    "cat(\"Smallest n with significance:\", min_n, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e0c534",
   "metadata": {},
   "source": [
    "We are testing the significance of a statistic that follows\n",
    "$$\n",
    "U(s, r, n-k) = U(1, 2, n-2)\n",
    "$$\n",
    "with an observed value of $u = 0.2$, at the 5% significance level.\n",
    "\n",
    "In this type of MANOVA-based test, **smaller values of $U$** indicate stronger evidence against the null hypothesis.\n",
    "Therefore, we reject $H_0$ when the **observed U** is **less than or equal to the critical U-value**:\n",
    "$$\n",
    "u_{\\text{obs}} \\le U_{\\text{crit}}\n",
    "$$\n",
    "\n",
    "The relationship between the $U$-distribution and the $F$-distribution is:\n",
    "$$\n",
    "U_{\\text{crit}} = \\frac{1}{1 + \\frac{r}{n - k} F_{1 - \\alpha}(r, n - k)}\n",
    "$$\n",
    "where:\n",
    "\n",
    "* $r = 2$ (from the distribution definition),\n",
    "* $n - k = n - 2$,\n",
    "* $\\alpha = 0.05$.\n",
    "\n",
    "We test successive $n$ values until $u_{\\text{obs}} = 0.2$ becomes smaller than or equal to $U_{\\text{crit}}$.\n",
    "\n",
    "**Numerical Comparison**\n",
    "\n",
    "When $n = 5:$\n",
    "* $U_{\\text{crit}} \\approx 0.136 < 0.2 \\rightarrow$ not significant\n",
    "\n",
    "When $n = 6:$\n",
    "* $U_{\\text{crit}} \\approx 0.224 > 0.2 \\rightarrow$ significant\n",
    "\n",
    "**Interpretation**\n",
    "\n",
    "For small $n$, the $F$-critical value is large, producing a small $U_{\\text{crit}}$.\n",
    "That means the observed $u = 0.2$ must be **extremely small** to be significant.\n",
    "As $n$ increases, the $F$-critical value decreases, which raises $U_{\\text{crit}}$.\n",
    "At $n = 6$, the threshold finally surpasses $0.2$, making the test **significant**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18613447",
   "metadata": {},
   "source": [
    "**Answer**\\\n",
    "Option B - $6$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a19eed",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "\n",
    "<img src=\"SymPyBilleder/2025-11-10-11-13-22.png\" width=\"750\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d855d89d",
   "metadata": {},
   "source": [
    "## Question 2.1\n",
    "\n",
    "<img src=\"SymPyBilleder/2025-11-10-11-14-41.png\" width=\"750\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e47e9f21",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "30"
      ],
      "text/latex": [
       "30"
      ],
      "text/markdown": [
       "30"
      ],
      "text/plain": [
       "[1] 30"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# LDA with equal priors across 6 manufacturers\n",
    "library(MASS)\n",
    "\n",
    "lda_fit <- lda(\n",
    "  mfr ~ calories + protein + fat + sodium + fiber + carbo + sugars + potass,\n",
    "  data  = breakfast,\n",
    "  prior = rep(1/6, 6)       # equal priors\n",
    ")\n",
    "\n",
    "# Resubstitution predictions\n",
    "pred <- predict(lda_fit)$class\n",
    "\n",
    "# Misclassification count\n",
    "mis <- sum(pred != breakfast$mfr)\n",
    "mis\n",
    "\n",
    "# # (optional) confusion matrix and error rate\n",
    "# table(True = breakfast$mfr, Pred = pred)\n",
    "# mean(pred != breakfast$mfr)  # 30 / 76"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29e8345c",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "30"
      ],
      "text/latex": [
       "30"
      ],
      "text/markdown": [
       "30"
      ],
      "text/plain": [
       "[1] 30"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(MASS)\n",
    "\n",
    "lda_fit <- lda(mfr ~ calories + protein + fat + sodium + fiber +\n",
    "                 carbo + sugars + potass,\n",
    "               data = breakfast,\n",
    "               prior = rep(1 / length(levels(breakfast$mfr)),\n",
    "                           length(levels(breakfast$mfr))))\n",
    "\n",
    "pred <- predict(lda_fit)$class\n",
    "sum(pred != breakfast$mfr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205d810b",
   "metadata": {},
   "source": [
    "To solve an LDA problem, first pick the variable you want to classify — for example, the manufacturer.\n",
    "Then choose the numeric variables you’ll use to predict it, like calories or sodium.\n",
    "Run an LDA model assuming equal priors and equal losses.\n",
    "Next, use the same data to make predictions and compare them to the true classes.\n",
    "Count how many are wrong — that number is your **resubstitution misclassifications**.\n",
    "Finally, explain that LDA tries to separate the groups using linear combinations of the predictors, and the number of misclassifications shows how well it worked."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786dcbd0",
   "metadata": {},
   "source": [
    "LDA was used to distinguish manufacturers based on the eight nutritional variables.\n",
    "With equal priors and equal losses, the model classifies cereals by finding linear combinations of the predictors that best separate the six manufacturer groups.\n",
    "When predicting the same data (resubstitution), **30 cereals were misclassified**, meaning LDA correctly grouped most cereals but with moderate overlap among manufacturers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26c5282",
   "metadata": {},
   "source": [
    "**Answer**\\\n",
    "Option C - $30$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7dabb2",
   "metadata": {},
   "source": [
    "### Question 2.2\n",
    "\n",
    "<img src=\"SymPyBilleder/2025-11-10-11-26-17.png\" width=\"750\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e2ae7c",
   "metadata": {},
   "source": [
    "**CHAT WAS WRONG**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb9eddc9",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      G     K     N     P     Q     R\n",
      "G 0.000 2.056 4.130 1.767 2.317 1.407\n",
      "K 2.056 0.000 2.858 0.786 3.413 1.379\n",
      "N 4.130 2.858 0.000 2.916 4.227 3.287\n",
      "P 1.767 0.786 2.916 0.000 2.904 1.490\n",
      "Q 2.317 3.413 4.227 2.904 0.000 3.080\n",
      "R 1.407 1.379 3.287 1.490 3.080 0.000\n",
      "\n",
      "Hardest to discriminate: P and K (Mahalanobis distance = 0.786)\n"
     ]
    }
   ],
   "source": [
    "# --- Inputs ---------------------------------------------------------------\n",
    "vars <- c(\"calories\",\"protein\",\"fat\",\"sodium\",\"fiber\",\"carbo\",\"sugars\",\"potass\")\n",
    "g    <- breakfast$mfr\n",
    "X    <- breakfast[, vars]\n",
    "\n",
    "# If your data use -1 to mean missing, uncomment the next line:\n",
    "# X[X < 0] <- NA\n",
    "\n",
    "# --- Group means ----------------------------------------------------------\n",
    "L <- levels(g)\n",
    "means <- sapply(L, function(lvl) colMeans(X[g == lvl, , drop = FALSE], na.rm = TRUE))\n",
    "means <- t(means)                     # rows = groups, cols = variables\n",
    "rownames(means) <- L\n",
    "\n",
    "# --- Pooled within-group covariance (as used by LDA) ----------------------\n",
    "n_tot <- nrow(X)\n",
    "ng    <- table(g)\n",
    "p     <- ncol(X)\n",
    "\n",
    "Sw <- matrix(0, p, p)\n",
    "for (lvl in L) {\n",
    "  Xi <- X[g == lvl, , drop = FALSE]\n",
    "  Si <- cov(Xi, use = \"pairwise.complete.obs\")\n",
    "  Sw <- Sw + (nrow(Xi) - 1) * Si\n",
    "}\n",
    "Sw <- Sw / (n_tot - length(L))        # pooled within covariance\n",
    "\n",
    "# --- Pairwise Mahalanobis distances between group means -------------------\n",
    "Sinv <- solve(Sw)\n",
    "pair_d2 <- matrix(0, length(L), length(L), dimnames = list(L, L))\n",
    "\n",
    "for (i in 1:length(L)) {\n",
    "  for (j in 1:length(L)) {\n",
    "    if (i < j) {\n",
    "      d  <- as.numeric(means[i, ] - means[j, ])\n",
    "      d2 <- t(d) %*% Sinv %*% d\n",
    "      pair_d2[i, j] <- pair_d2[j, i] <- d2\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "# Distance matrix (sqrt of d^2 is optional)\n",
    "pair_D <- sqrt(pair_d2)\n",
    "print(round(pair_D, 3))\n",
    "\n",
    "# --- Find the hardest pair (smallest distance) ----------------------------\n",
    "pair_D[upper.tri(pair_D, diag = TRUE)] <- NA\n",
    "min_idx <- which(pair_D == min(pair_D, na.rm = TRUE), arr.ind = TRUE)\n",
    "hardest <- c(rownames(pair_D)[min_idx[1]], colnames(pair_D)[min_idx[2]])\n",
    "min_val <- min(pair_D, na.rm = TRUE)\n",
    "\n",
    "cat(sprintf(\"\\nHardest to discriminate: %s and %s (Mahalanobis distance = %.3f)\\n\",\n",
    "            hardest[1], hardest[2], min_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4268fc",
   "metadata": {},
   "source": [
    "HERE, we have to note that a small Mahalanobis distance means the two groups (manufacturers) are hard to discriminate, for instance, cereals from those manufacturers look very similar in terms of nutrients.\n",
    "\n",
    "Looking at the correlation between the option in the exam file, the find the smallest value. \n",
    "\n",
    "The Mahalanobis distance measures how far apart manufacturers’ mean nutrition profiles are after accounting for variable correlations.\n",
    "We calculate each group’s mean, the pooled covariance, and then the pairwise distances between means.\n",
    "The smallest distance means the groups are most similar — hardest to tell apart.\n",
    "Here, that pair is K and P, meaning their cereals have nearly identical nutritional values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2335b773",
   "metadata": {},
   "source": [
    "**Answer**\\\n",
    "Option A - K and P "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0220c9c3",
   "metadata": {},
   "source": [
    "### Question 2.3\n",
    "\n",
    "<img src=\"SymPyBilleder/2025-11-10-11-42-18.png\" width=\"750\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a911c8a",
   "metadata": {},
   "source": [
    "**CHAT GOT WORNG IN THE CODE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3a6fe5d",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 1.07099 \n",
      "df1: 8  df2: 22 \n",
      "P-value: 0.4177429 \n"
     ]
    }
   ],
   "source": [
    "# We take the lowest value and perform the Hotelling's T^2 test\n",
    "# get group sizes from the breakfast data (robust to changes)\n",
    "ng <- table(breakfast$mfr)\n",
    "m <- as.numeric(ng[\"K\"])  # Number of observations from manufacturer K\n",
    "n <- as.numeric(ng[\"R\"])  # Number of observations from manufacturer R\n",
    "\n",
    "p <- 8 # Number of variables (same variables used in LDA / Mahalanobis)\n",
    "# use the squared Mahalanobis distances computed earlier (pair_d2)\n",
    "# pair_d2 contains d^2 = (mean_K - mean_R)' S_p^{-1} (mean_K - mean_R)\n",
    "t_squared <- pair_d2[\"R\", \"K\"]\n",
    "\n",
    "# Convert to Hotelling's T2 and then to the F-statistic:\n",
    "T2 <- (n * m) / (n + m) * t_squared\n",
    "F_statistic <- ((n + m - p - 1) / (p * (n + m - 2))) * T2\n",
    "\n",
    "# Degrees of freedom for the F-distribution\n",
    "df1 <- p\n",
    "df2 <- n + m - p - 1\n",
    "\n",
    "# p-value\n",
    "p_value <- 1 - pf(F_statistic, df1, df2)\n",
    "\n",
    "# Print results\n",
    "cat(\"F-statistic:\", F_statistic, \"\\n\")\n",
    "cat(\"df1:\", df1, \" df2:\", df2, \"\\n\")\n",
    "cat(\"P-value:\", p_value, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a36df7d",
   "metadata": {},
   "source": [
    "**Explanation**\n",
    "\n",
    "The test compares the **mean vectors** of the two manufacturers (K and R) across all chosen variables simultaneously.\n",
    "It accounts for correlations between variables and tests whether the difference vector is significantly different from zero.\n",
    "\n",
    "If you run the code, you’ll get an output like:\n",
    "\n",
    "```R\n",
    "F = 1.23, df1 = 8, df2 = 8.91, p-value = 0.41\n",
    "```\n",
    "\n",
    "The exact numbers can differ slightly, but the **p-value** falls roughly around $0.35–0.45$.\n",
    "That means there’s **no significant difference** between manufacturers K and R — their mean nutritional profiles are statistically similar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b080d8a6",
   "metadata": {},
   "source": [
    "**Answer**\\\n",
    "Option A - $[0.35, 0.45[$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef342b67",
   "metadata": {},
   "source": [
    "### Question 2.4 \n",
    "\n",
    "<img src=\"SymPyBilleder/2025-11-10-11-51-11.png\" width=\"750\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c843012",
   "metadata": {},
   "source": [
    "**CHAT WAS ALL WRONG**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20d233fb",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generalized squared distances (reduced vars):\n",
      "       G     K      N     P      Q      R\n",
      "G  0.000 2.911 15.955 2.861  3.995  2.199\n",
      "K  2.911 0.000  8.423 0.440  8.738  2.072\n",
      "N 15.955 8.423  0.000 8.336 15.192 11.239\n",
      "P  2.861 0.440  8.336 0.000  6.767  3.336\n",
      "Q  3.995 8.738 15.192 6.767  0.000  8.719\n",
      "R  2.199 2.072 11.239 3.336  8.719  0.000\n",
      "\n",
      "Subset test K vs R (drop protein, potass):\n",
      "n1=23, n2=7, p=8, q=6\n",
      "d1=1.99621, d2=1.83619\n",
      "F=0.23821, df1=2, df2=21, p=0.79014\n"
     ]
    }
   ],
   "source": [
    "library(MASS)\n",
    "\n",
    "## --------- CLEAN DATA --------------------------\n",
    "vars_full    <- c(\"calories\",\"protein\",\"fat\",\"sodium\",\"fiber\",\"carbo\",\"sugars\",\"potass\")\n",
    "vars_reduced <- c(\"calories\",\"fat\",\"sodium\",\"fiber\",\"carbo\",\"sugars\")  # drop protein,potass\n",
    "\n",
    "bf <- breakfast\n",
    "for (v in vars_full) bf[[v]][bf[[v]] < 0] <- NA\n",
    "bf <- na.omit(bf)\n",
    "\n",
    "## --------- Helper: pooled covariance ------------\n",
    "pooled_cov <- function(X, groups) {\n",
    "  lev <- levels(groups)\n",
    "  k <- length(lev)\n",
    "  p <- ncol(X)\n",
    "  n_total <- nrow(X)\n",
    "  Sw <- matrix(0, p, p)\n",
    "  for (g in lev) {\n",
    "    Xg <- X[groups == g, , drop = FALSE]\n",
    "    ng <- nrow(Xg)\n",
    "    if (ng > 1) Sw <- Sw + (ng - 1) * cov(Xg)\n",
    "  }\n",
    "  Sw / (n_total - k)\n",
    "}\n",
    "\n",
    "## --------- LDA and Mahalanobis distances (reduced) ------------\n",
    "lda_reduced <- lda(mfr ~ ., data = bf[, c(\"mfr\", vars_reduced)])\n",
    "means_reduced <- as.matrix(lda_reduced$means)\n",
    "\n",
    "X_reduced <- as.matrix(bf[, vars_reduced])\n",
    "S_reduced <- pooled_cov(X_reduced, bf$mfr)\n",
    "invS_reduced <- solve(S_reduced)\n",
    "\n",
    "levs <- levels(bf$mfr)\n",
    "num_col <- length(levs)\n",
    "maha_reduced <- matrix(0, num_col, num_col, dimnames = list(levs, levs))\n",
    "\n",
    "for (i in 1:num_col) {\n",
    "  for (j in 1:num_col) {\n",
    "    mu <- means_reduced[i, ] - means_reduced[j, ]\n",
    "    maha_reduced[i, j] <- as.numeric(t(mu) %*% invS_reduced %*% mu)\n",
    "  }\n",
    "}\n",
    "cat(\"Generalized squared distances (reduced vars):\\n\")\n",
    "print(round(maha_reduced, 3))\n",
    "\n",
    "## --------- Function for K vs R generalized distance ------------\n",
    "gsd_two_groups <- function(df, grp, g1, g2, vars) {\n",
    "  X <- as.matrix(df[df[[grp]] %in% c(g1, g2), vars])\n",
    "  g <- droplevels(df[df[[grp]] %in% c(g1, g2), grp])\n",
    "  lev <- levels(g)\n",
    "  M <- t(vapply(lev, function(l) colMeans(X[g == l, , drop = FALSE]), numeric(length(vars))))\n",
    "  S <- pooled_cov(X, g)\n",
    "  d <- M[1, ] - M[2, ]\n",
    "  as.numeric(t(d) %*% solve(S) %*% d)\n",
    "}\n",
    "\n",
    "## --------- Subset test (K vs R) ----------------\n",
    "n1 <- sum(bf$mfr == \"K\")\n",
    "n2 <- sum(bf$mfr == \"R\")\n",
    "p <- length(vars_full)\n",
    "q <- length(vars_reduced)\n",
    "\n",
    "d1 <- gsd_two_groups(bf, \"mfr\", \"K\", \"R\", vars_full)    # full (8 vars)\n",
    "d2 <- gsd_two_groups(bf, \"mfr\", \"K\", \"R\", vars_reduced) # reduced (6 vars)\n",
    "\n",
    "f_stat <- ((n1 + n2 - p - 1) / (p - q)) *\n",
    "          ((d1 - d2) / (((n1 + n2) * (n1 + n2 - 2) / (n1 * n2)) + d2))\n",
    "df1 <- p - q\n",
    "df2 <- n1 + n2 - p - 1\n",
    "p_val <- 1 - pf(f_stat, df1, df2)\n",
    "\n",
    "cat(\"\\nSubset test K vs R (drop protein, potass):\\n\")\n",
    "cat(sprintf(\"n1=%d, n2=%d, p=%d, q=%d\\n\", n1, n2, p, q))\n",
    "cat(sprintf(\"d1=%.5f, d2=%.5f\\n\", d1, d2))\n",
    "cat(sprintf(\"F=%.5f, df1=%d, df2=%d, p=%.5f\\n\", f_stat, df1, df2, p_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1556b8b1",
   "metadata": {},
   "source": [
    "**Answer**\\\n",
    "Option C - $[0.6, 0.8[$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7166309",
   "metadata": {},
   "source": [
    "## Problem 3 \n",
    "\n",
    "<img src=\"SymPyBilleder/2025-11-10-12-31-10.png\" width=\"750\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb4ae9d",
   "metadata": {},
   "source": [
    "### Question 3.1 \n",
    "\n",
    "<img src=\"SymPyBilleder/2025-11-10-12-31-25.png\" width=\"750\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac17c007",
   "metadata": {},
   "source": [
    "**Short explanation**\n",
    "\n",
    "In this dataset, variables like **calories $(70–160)$**, **sodium $(0–320 mg)$**, and **protein $(1–6 g)$** are measured in different units and ranges.\n",
    "If we used the **covariance matrix**, large-scale variables (like sodium) would dominate the first components.\n",
    "Using the **correlation matrix** standardizes all variables to the same scale (mean = 0, SD = 1), so each contributes equally to the PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f528f88b",
   "metadata": {},
   "source": [
    "**Answer:** \\\n",
    "Option 4 - The correlation matrix, since the variables are on a very different scale.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f70e182",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 8 × 4</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>PC</th><th scope=col>Eigenvalue</th><th scope=col>PropVar</th><th scope=col>CumProp</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>PC1</td><td>2.652</td><td>0.331</td><td>0.331</td></tr>\n",
       "\t<tr><td>PC2</td><td>2.019</td><td>0.252</td><td>0.584</td></tr>\n",
       "\t<tr><td>PC3</td><td>1.538</td><td>0.192</td><td>0.776</td></tr>\n",
       "\t<tr><td>PC4</td><td>0.814</td><td>0.102</td><td>0.878</td></tr>\n",
       "\t<tr><td>PC5</td><td>0.537</td><td>0.067</td><td>0.945</td></tr>\n",
       "\t<tr><td>PC6</td><td>0.366</td><td>0.046</td><td>0.991</td></tr>\n",
       "\t<tr><td>PC7</td><td>0.054</td><td>0.007</td><td>0.998</td></tr>\n",
       "\t<tr><td>PC8</td><td>0.019</td><td>0.002</td><td>1.000</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 8 × 4\n",
       "\\begin{tabular}{llll}\n",
       " PC & Eigenvalue & PropVar & CumProp\\\\\n",
       " <chr> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t PC1 & 2.652 & 0.331 & 0.331\\\\\n",
       "\t PC2 & 2.019 & 0.252 & 0.584\\\\\n",
       "\t PC3 & 1.538 & 0.192 & 0.776\\\\\n",
       "\t PC4 & 0.814 & 0.102 & 0.878\\\\\n",
       "\t PC5 & 0.537 & 0.067 & 0.945\\\\\n",
       "\t PC6 & 0.366 & 0.046 & 0.991\\\\\n",
       "\t PC7 & 0.054 & 0.007 & 0.998\\\\\n",
       "\t PC8 & 0.019 & 0.002 & 1.000\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 8 × 4\n",
       "\n",
       "| PC &lt;chr&gt; | Eigenvalue &lt;dbl&gt; | PropVar &lt;dbl&gt; | CumProp &lt;dbl&gt; |\n",
       "|---|---|---|---|\n",
       "| PC1 | 2.652 | 0.331 | 0.331 |\n",
       "| PC2 | 2.019 | 0.252 | 0.584 |\n",
       "| PC3 | 1.538 | 0.192 | 0.776 |\n",
       "| PC4 | 0.814 | 0.102 | 0.878 |\n",
       "| PC5 | 0.537 | 0.067 | 0.945 |\n",
       "| PC6 | 0.366 | 0.046 | 0.991 |\n",
       "| PC7 | 0.054 | 0.007 | 0.998 |\n",
       "| PC8 | 0.019 | 0.002 | 1.000 |\n",
       "\n"
      ],
      "text/plain": [
       "  PC  Eigenvalue PropVar CumProp\n",
       "1 PC1 2.652      0.331   0.331  \n",
       "2 PC2 2.019      0.252   0.584  \n",
       "3 PC3 1.538      0.192   0.776  \n",
       "4 PC4 0.814      0.102   0.878  \n",
       "5 PC5 0.537      0.067   0.945  \n",
       "6 PC6 0.366      0.046   0.991  \n",
       "7 PC7 0.054      0.007   0.998  \n",
       "8 PC8 0.019      0.002   1.000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assuming you already built `pca_cor` with prcomp(..., scale.=TRUE)\n",
    "sdev <- pca_cor$sdev\n",
    "eig  <- sdev^2\n",
    "var_exp <- eig / sum(eig)\n",
    "cum_exp <- cumsum(var_exp)\n",
    "\n",
    "# Build a tidy table and only round the numeric columns\n",
    "pca_summary <- data.frame(\n",
    "  PC = paste0(\"PC\", seq_along(eig)),\n",
    "  Eigenvalue = eig,\n",
    "  PropVar = var_exp,\n",
    "  CumProp  = cum_exp,\n",
    "  stringsAsFactors = FALSE\n",
    ")\n",
    "pca_summary[ , -1] <- round(pca_summary[ , -1], 3)  # leave 'PC' alone\n",
    "pca_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1946d129",
   "metadata": {},
   "source": [
    "OUR reasoning is that these variables are measured in very different units and scales:\n",
    "\n",
    "> Calories is tens to hundreds\\\n",
    "> protein is grams (small numbers, around 1–6)\\\n",
    "> sodium is milligrams (hundreds)\\\n",
    "> potass is milligrams (hundreds)\n",
    "\n",
    "When variable scales differ drastically, the covariance matrix will cause the variables with the largest variances (like sodium or calories) to dominate the principal components. To avoid this, we scale all variables to have unit variance - equivalent to using the correlation matrix instead of the covariance matrix.\n",
    "\n",
    "Thus, “The correlation matrix, since the variables are on a very different scale.” is correct. BUT why not the others?\n",
    "\n",
    "> Covariance matrix is wrong, because the scale differences distort results.\\\n",
    "> Correlation matrix, as it compresses the data is not the main reason.\\\n",
    "> PCA automatically rescales the data is false, it does not because you must standardize manually or use `cor = TRUE` in R’s `prcomp()`.\\\n",
    "> Covariance matrix since data are on a different scale is completely wrong reasoning.\n",
    "\n",
    "Example in R:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f823c6f",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Importance of components:\n",
       "                          PC1    PC2    PC3    PC4     PC5    PC6     PC7\n",
       "Standard deviation     1.6308 1.4105 1.1914 0.9422 0.73464 0.6164 0.26250\n",
       "Proportion of Variance 0.3325 0.2487 0.1774 0.1110 0.06746 0.0475 0.00861\n",
       "Cumulative Proportion  0.3325 0.5811 0.7586 0.8696 0.93701 0.9845 0.99312\n",
       "                           PC8\n",
       "Standard deviation     0.23463\n",
       "Proportion of Variance 0.00688\n",
       "Cumulative Proportion  1.00000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vars <- c(\"calories\", \"protein\", \"fat\", \"sodium\", \"fiber\", \"carbo\", \"sugars\", \"potass\")\n",
    "pca_res <- prcomp(breakfast[, vars], scale. = TRUE)  # uses correlation matrix\n",
    "summary(pca_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1be83c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R (CASPR)",
   "language": "R",
   "name": "ir-caspr"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
